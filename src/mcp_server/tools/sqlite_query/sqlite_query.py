"""
sqlite_query Tool

è®€å– SQLite .db æª”æ¡ˆï¼ŒåŸ·è¡Œ SQL æŸ¥è©¢èˆ‡æ“ä½œã€‚
æ”¯æ´ SELECT, INSERT, UPDATE, DELETE ç­‰æ“ä½œã€‚
"""

import logging
import sqlite3
from datetime import datetime
from pathlib import Path
from typing import Any

from mcp_server.schemas import ExecutionResult
from mcp_server.tools.base import registry

logger = logging.getLogger(__name__)

# é è¨­è³‡æ–™åº«è·¯å¾‘ï¼ˆå¯é€éç’°å¢ƒè®Šæ•¸è¦†è“‹ï¼‰
DEFAULT_DB_PATH = "/mnt/public/Develop/Projects/external_projects/gpt-load/data/gpt-load.db"

# å®‰å…¨é™åˆ¶
MAX_RESULTS = 500  # å–®æ¬¡æŸ¥è©¢æœ€å¤§è¿”å›ç­†æ•¸
MAX_SQL_LENGTH = 10000  # SQL èªå¥æœ€å¤§é•·åº¦
FORBIDDEN_KEYWORDS = [  # ç¦æ­¢çš„å±éšªæ“ä½œï¼ˆå¯æ ¹æ“šéœ€æ±‚èª¿æ•´ï¼‰
    # "DROP", "ALTER", "CREATE", -- è¦–éœ€æ±‚é–‹æ”¾
]


def validate_sql(sql: str) -> tuple[bool, str]:
    """
    åŸºæœ¬çš„ SQL å®‰å…¨æª¢æŸ¥
    
    Returns:
        (is_valid, error_message)
    """
    if not sql or not isinstance(sql, str):
        return False, "SQL èªå¥ä¸èƒ½ç‚ºç©º"
    
    sql_upper = sql.upper().strip()
    
    if len(sql) > MAX_SQL_LENGTH:
        return False, f"SQL èªå¥éé•·ï¼ˆè¶…é {MAX_SQL_LENGTH} å­—å…ƒï¼‰"
    
    # æª¢æŸ¥ç¦æ­¢çš„é—œéµå­—
    for keyword in FORBIDDEN_KEYWORDS:
        if keyword in sql_upper:
            return False, f"ç¦æ­¢åŸ·è¡ŒåŒ…å« {keyword} çš„æ“ä½œ"
    
    return True, ""


def format_value(value: Any) -> str:
    """æ ¼å¼åŒ–å–®ä¸€å€¼ç”¨æ–¼é¡¯ç¤º"""
    if value is None:
        return "NULL"
    if isinstance(value, bytes):
        return f"<BLOB {len(value)} bytes>"
    if isinstance(value, str) and len(value) > 200:
        return value[:200] + "...[truncated]"
    return str(value)


def format_row(row: tuple, columns: list[str]) -> str:
    """æ ¼å¼åŒ–å–®è¡Œè³‡æ–™"""
    parts = []
    for col, val in zip(columns, row):
        parts.append(f"{col}={format_value(val)}")
    return " | ".join(parts)


def execute_sql_internal(db_path: str, sql: str, params: list[Any] | None = None) -> ExecutionResult:
    """
    å…§éƒ¨åŸ·è¡Œ SQL çš„å‡½æ•¸
    
    Args:
        db_path: è³‡æ–™åº«æª”æ¡ˆè·¯å¾‘
        sql: SQL èªå¥
        params: åƒæ•¸åˆ—è¡¨ï¼ˆç”¨æ–¼åƒæ•¸åŒ–æŸ¥è©¢ï¼‰
    
    Returns:
        ExecutionResult
    """
    start_time = datetime.now()
    
    # é©—è­‰ SQL
    is_valid, error_msg = validate_sql(sql)
    if not is_valid:
        return ExecutionResult(
            success=False,
            error_type="ValidationError",
            error_message=error_msg,
            execution_time="0.000s",
        )
    
    # æª¢æŸ¥è³‡æ–™åº«æª”æ¡ˆ
    db_file = Path(db_path)
    if not db_file.exists():
        return ExecutionResult(
            success=False,
            error_type="FileNotFoundError",
            error_message=f"è³‡æ–™åº«æª”æ¡ˆä¸å­˜åœ¨: {db_path}",
            execution_time="0.000s",
        )
    
    try:
        conn = sqlite3.connect(str(db_file))
        conn.row_factory = sqlite3.Row  # ä½¿ç”¨ Row å·¥å» ä¾¿æ–¼å–å¾—æ¬„ä½å
        cursor = conn.cursor()
        
        # å•Ÿç”¨å¤–éµç´„æŸ
        cursor.execute("PRAGMA foreign_keys = ON")
        
        # åŸ·è¡Œ SQL
        if params:
            cursor.execute(sql, params)
        else:
            cursor.execute(sql)
        
        # åˆ¤æ–·æ“ä½œé¡å‹
        sql_upper = sql.upper().strip()
        is_query = sql_upper.startswith(("SELECT", "PRAGMA", "EXPLAIN", "WITH"))
        
        if is_query:
            # æŸ¥è©¢æ“ä½œï¼šè¿”å›çµæœ
            rows = cursor.fetchmany(MAX_RESULTS + 1)  # å¤šå–ä¸€ç­†ç”¨æ–¼åˆ¤æ–·æ˜¯å¦æˆªæ–·
            columns = [desc[0] for desc in cursor.description] if cursor.description else []
            
            truncated = len(rows) > MAX_RESULTS
            if truncated:
                rows = rows[:MAX_RESULTS]
            
            # æ ¼å¼åŒ–è¼¸å‡º
            output_lines = []
            output_lines.append(f"ğŸ“Š æŸ¥è©¢çµæœ: {len(rows)} ç­†{' (å·²æˆªæ–·)' if truncated else ''}")
            output_lines.append(f"ğŸ“‹ æ¬„ä½: {', '.join(columns)}")
            output_lines.append("-" * 80)
            
            for row in rows:
                row_dict = dict(row)
                formatted = " | ".join(f"{k}={format_value(v)}" for k, v in row_dict.items())
                output_lines.append(formatted)
            
            # å¦‚æœæ˜¯ PRAGMAï¼Œä¹Ÿè¿”å›çµæ§‹åŒ–è³‡æ–™
            if sql_upper.startswith("PRAGMA"):
                output_lines.append("\nğŸ“ çµæ§‹åŒ–è³‡æ–™:")
                for row in rows:
                    output_lines.append(str(dict(row)))
            
            stdout = "\n".join(output_lines)
            conn.close()
            
            execution_time = (datetime.now() - start_time).total_seconds()
            return ExecutionResult(
                success=True,
                stdout=stdout,
                returncode=0,
                execution_time=f"{execution_time:.3f}s",
                metadata={
                    "db_path": db_path,
                    "row_count": len(rows),
                    "truncated": truncated,
                    "columns": columns,
                },
            )
        else:
            # å¯«å…¥æ“ä½œï¼šè¿”å›å½±éŸ¿ç­†æ•¸
            affected_rows = cursor.rowcount
            conn.commit()
            conn.close()
            
            execution_time = (datetime.now() - start_time).total_seconds()
            
            # åˆ¤æ–·æ“ä½œé¡å‹
            if "INSERT" in sql_upper:
                op_type = "æ’å…¥"
            elif "UPDATE" in sql_upper:
                op_type = "æ›´æ–°"
            elif "DELETE" in sql_upper:
                op_type = "åˆªé™¤"
            else:
                op_type = "åŸ·è¡Œ"
            
            stdout = f"âœ… {op_type}æˆåŠŸ: å½±éŸ¿ {affected_rows} ç­†è³‡æ–™"
            
            return ExecutionResult(
                success=True,
                stdout=stdout,
                returncode=0,
                execution_time=f"{execution_time:.3f}s",
                metadata={
                    "db_path": db_path,
                    "affected_rows": affected_rows,
                },
            )
    
    except sqlite3.Error as e:
        logger.exception(f"SQLite éŒ¯èª¤: {e}")
        return ExecutionResult(
            success=False,
            error_type="SQLiteError",
            error_message=str(e),
            stderr=str(e),
            returncode=1,
            execution_time=f"{(datetime.now() - start_time).total_seconds():.3f}s",
            metadata={"db_path": db_path},
        )
    except Exception as e:
        logger.exception(f"åŸ·è¡Œ SQL æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return ExecutionResult(
            success=False,
            error_type=type(e).__name__,
            error_message=str(e),
            stderr=str(e),
            returncode=1,
            execution_time=f"{(datetime.now() - start_time).total_seconds():.3f}s",
            metadata={"db_path": db_path},
        )


@registry.register(
    name="sqlite_query",
    description="åŸ·è¡Œ SQLite SQL æŒ‡ä»¤ï¼Œæ“ä½œ .db è³‡æ–™åº«æª”æ¡ˆã€‚æ”¯æ´ SELECT, INSERT, UPDATE, DELETE ç­‰ SQL èªæ³•ã€‚é è¨­ä½¿ç”¨ gpt-load.dbã€‚",
    input_schema={
        "type": "object",
        "properties": {
            "sql": {
                "type": "string",
                "description": "è¦åŸ·è¡Œçš„ SQL æŒ‡ä»¤ï¼Œä¾‹å¦‚ 'SELECT * FROM api_keys LIMIT 10'",
            },
            "database": {
                "type": "string",
                "description": "è³‡æ–™åº«æª”æ¡ˆè·¯å¾‘ï¼ˆå¯é¸ï¼Œé è¨­ä½¿ç”¨ gpt-load.dbï¼‰",
                "default": DEFAULT_DB_PATH,
            },
            "params": {
                "type": "array",
                "description": "SQL åƒæ•¸åˆ—è¡¨ï¼ˆç”¨æ–¼åƒæ•¸åŒ–æŸ¥è©¢ï¼Œé˜²æ­¢ SQL æ³¨å…¥ï¼‰",
                "items": {"type": ["string", "number", "boolean", "null"]},
            },
        },
        "required": ["sql"],
    },
)
async def handle_sqlite_query(args: dict[str, Any]) -> ExecutionResult:
    """è™•ç† sqlite_query è«‹æ±‚"""
    sql = args.get("sql")
    
    if not sql or not isinstance(sql, str):
        raise ValueError("å¿…é ˆæä¾›æœ‰æ•ˆçš„ sql åƒæ•¸")
    
    db_path = args.get("database", DEFAULT_DB_PATH)
    params = args.get("params")
    
    logger.info(f"åŸ·è¡Œ SQLite æŸ¥è©¢: {sql[:100]}... (db={db_path})")
    
    return execute_sql_internal(db_path, sql, params)


@registry.register(
    name="sqlite_tables",
    description="åˆ—å‡º SQLite è³‡æ–™åº«ä¸­çš„æ‰€æœ‰è¡¨åŠå…¶çµæ§‹ã€‚",
    input_schema={
        "type": "object",
        "properties": {
            "database": {
                "type": "string",
                "description": "è³‡æ–™åº«æª”æ¡ˆè·¯å¾‘ï¼ˆå¯é¸ï¼Œé è¨­ä½¿ç”¨ gpt-load.dbï¼‰",
                "default": DEFAULT_DB_PATH,
            },
        },
        "required": [],
    },
)
async def handle_sqlite_tables(args: dict[str, Any]) -> ExecutionResult:
    """åˆ—å‡ºè³‡æ–™åº«ä¸­çš„æ‰€æœ‰è¡¨"""
    db_path = args.get("database", DEFAULT_DB_PATH)
    
    logger.info(f"åˆ—å‡ºè³‡æ–™åº«è¡¨: {db_path}")
    
    # é©—è­‰æª”æ¡ˆ
    db_file = Path(db_path)
    if not db_file.exists():
        return ExecutionResult(
            success=False,
            error_type="FileNotFoundError",
            error_message=f"è³‡æ–™åº«æª”æ¡ˆä¸å­˜åœ¨: {db_path}",
            execution_time="0.000s",
        )
    
    start_time = datetime.now()
    
    try:
        conn = sqlite3.connect(str(db_file))
        cursor = conn.cursor()
        
        # å–å¾—æ‰€æœ‰è¡¨
        cursor.execute("""
            SELECT name, type 
            FROM sqlite_master 
            WHERE type IN ('table', 'view') 
            ORDER BY type, name
        """)
        tables = cursor.fetchall()
        
        output_lines = []
        output_lines.append(f"ğŸ“ è³‡æ–™åº«: {db_path}")
        output_lines.append(f"ğŸ“Š å¤§å°: {db_file.stat().st_size / 1024:.2f} KB")
        output_lines.append(f"ğŸ“‹ å…± {len(tables)} å€‹è¡¨/è¦–åœ–\n")
        
        table_info = []
        
        for table_name, table_type in tables:
            if table_name.startswith("sqlite_"):
                continue  # è·³éç³»çµ±è¡¨
            
            # å–å¾—è¡¨çµæ§‹
            cursor.execute(f"PRAGMA table_info({table_name})")
            columns = cursor.fetchall()
            
            # å–å¾—ç­†æ•¸
            cursor.execute(f"SELECT COUNT(*) FROM {table_name}")
            count = cursor.fetchone()[0]
            
            output_lines.append(f"{'ğŸ“Œ' if table_type == 'table' else 'ğŸ‘ï¸'} {table_name}")
            output_lines.append(f"   é¡å‹: {table_type}")
            output_lines.append(f"   ç­†æ•¸: {count:,}")
            output_lines.append(f"   æ¬„ä½: {len(columns)}")
            
            col_info = []
            for col in columns:
                col_name = col[1]
                col_type = col[2]
                col_pk = " ğŸ”‘" if col[5] else ""
                col_info.append(f"{col_name} ({col_type}){col_pk}")
            
            output_lines.append(f"   çµæ§‹: {', '.join(col_info)}")
            output_lines.append("")
            
            table_info.append({
                "name": table_name,
                "type": table_type,
                "row_count": count,
                "columns": [{"name": c[1], "type": c[2], "pk": bool(c[5])} for c in columns],
            })
        
        conn.close()
        
        execution_time = (datetime.now() - start_time).total_seconds()
        
        return ExecutionResult(
            success=True,
            stdout="\n".join(output_lines),
            returncode=0,
            execution_time=f"{execution_time:.3f}s",
            metadata={
                "db_path": db_path,
                "table_count": len(tables),
                "tables": table_info,
            },
        )
    
    except Exception as e:
        logger.exception(f"åˆ—å‡ºè³‡æ–™åº«è¡¨æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return ExecutionResult(
            success=False,
            error_type=type(e).__name__,
            error_message=str(e),
            stderr=str(e),
            returncode=1,
            execution_time=f"{(datetime.now() - start_time).total_seconds():.3f}s",
            metadata={"db_path": db_path},
        )